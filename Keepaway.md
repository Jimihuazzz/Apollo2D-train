# 关于Keepaway的相关研究

### 概述

简单描述Keepaway，是UT Villa发明的一种关于Robocup2D球队训练的一种工具，相关链接在此

    https://www.cs.utexas.edu/~AustinVilla/sim/keepaway/

结论：有价值，但是现阶段不值得做。

补充：Keepaway在国内足球叫做“抢圈”，玩法是两队人在一个相对固定的区域内，一队人负责持球传接练习，另外一队人则负责干扰抢断。大多数适用于热身以及业余/职业球队日常训练，能够很好的锻炼球员的配合和传接球基本功。同时由于规则的限制，通常以持球队伍能够持球的时间作为评判的标准（因为最终球都会落到抢球队伍的手中）。

## 原因

#### 原因一 技术支持

这个项目是由UT（德克萨斯大学）来维护的，然而该大学的重心已经转向仿真3D领域，该项目在2011年已经停止维护，所以我们并不会获得更大程度的技术支持。

#### 原因二 耦合难度

根据组长lyb对于现有Apollo2D的评价，由于我们人员断代，不能很好的阅读源码，所以现有的4后卫不能进行大规模的修改。**然而根据我个人的判断**，Keepaway的训练方式很大程度上要求整个球队是一个整体，即需要每个球员都能够传接球，进行有效配合，在不改动核心代码以及不修改决策树的情况下很难做到。所以说即使在Keepaway现有工具的训练下，很难将现有代码和这种偏向控球的打法结合。

顺便说下我对于现在Apollo2D的开发的看法，由于人员流动机制，决定了2D组现在仅仅能够通过Sprint（亚马逊的开发方式，类似于国内所说的小步快跑）进行开发。我们很难去重构代码（**也许仅限于现在**），所以进行HFO等方式会更有利于我们进行开发。

#### 原因三 难度

我们现有的技术力不足以支持这样一个机器学习项目（即使可以，性价比也不会很高），原因是虽然该项目的Reward的显而易见的（即持球时间），然而真实世界的足球告诉我们，持球时间长未必能够获胜——Apollo2D亦然如此。

另外我们很难在该项目中划分状态，如果每一次查询到新的持球人就是一个状态，那么显然系统会急剧演变成“球烫脚”/“球黏脚”的两种情况，然而每一个周期时间去作为一个状态来划分游戏阶段显然也是很不科学的，因为Reward不会及时刷新，在一定训练下也会坍缩成前者的情况。UT的研究小组也提到了这一点。

同时多Agent的协同也让人十分头疼，这是众所周知的难点，因为如果没有良好的模型构建最终会很快变成仅有1/2人的游戏（想象下训练的最终效果是两个人的传接球越来越默契，但是其他几个人呆若木鸡的样子吧）

## 总结

为什么我们还不做HFO呢？